---
title: "gnomAD cleaning"
author: "Christelle Colin-Leitzinger"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_float: yes
    toc_collapsed: no
    theme: cerulean
    highlight: pygments
    df_print: paged
editor_options:
  chunk_output_type: console
---

<style type="text/css">
h1.title {
  font-size: 25px;
}
.figure {
   margin-top: 25px;
   margin-bottom: 25px;
}

table {
    margin-top: 25px;
    <!-- margin-bottom: 100px !important; -->
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      cache = FALSE,
                      fig.align='center'#, fig.show='hold'
                      )
options(gtsummary.print_engine = "gt")
options(gtsummary.as_gt.addl_cmds = "gt::tab_options(table.font.size = 12, data_row.padding = gt::px(1))")
```


<style>
div.blue { background-color:#0099CC; border-radius: 5px; padding: 20px; font-size: 38px}
</style>
<div class = "blue">

<span style="color: white;">Manuscript</span>

</div>
<br>

```{r library, include=FALSE}
library(tidyverse)
library(e1071)
library(purrr)
```

```{r load}
path <- fs::path("", "Volumes", "Lab_Gillis", "Christelle")
gnomad <-
  read.delim(paste0(path, "/gnomAD_raw_data/dnmt3a_data.vcf.gz"), 
             header = FALSE, 
             col.names = c("X.CHROM", "POS", "ID", "REF", "ALT", "QUAL", "FILTER", "INFO"))
```

# 1. Data cleaning
As an example I selected all the variant DNMT3A. Here is a example of the raw data.
```{r}
head(gnomad)
```

I first extracted the age bin and sample counts from the `INFO` variable.
```{r}
gnomad_decoded <- gnomad %>% 
  mutate(X.CHROM = str_remove(X.CHROM, "chr")) %>% 
  unite(IDs, c(X.CHROM, POS, REF, ALT), sep = "-") %>% 
  # mutate(IDs = factor(row_number())) %>% 
  
  # ab_hist_alt_bin_freq,Number=A,Type=String,Description="Histogram for AB in heterozygous individuals; 
  # bin edges are: 0.00|0.05|0.10|0.15|0.20|0.25|0.30|0.35|0.40|0.45|0.50|0.55|0.60|0.65|0.70|0.75|0.80|0.85|0.90|0.95|1.00">
  
  # age_hist_het_bin_freq,Number=A,Type=String,Description="Histogram of ages of heterozygous individuals; 
  # bin edges are: 30.0|35.0|40.0|45.0|50.0|55.0|60.0|65.0|70.0|75.0|80.0; 
  # total number of individuals of any genotype bin: 2547|3423|4546|8487|10355|12693|11933|10534|8882|5991|4136|1935">
  mutate(age_hist_het_bin_freq = str_match(INFO, "age_hist_het_bin_freq=(.*?);")[,2]) %>%
  
  # "Count of age values falling below lowest histogram bin edge for heterozygous individuals">
  mutate("<30" = as.numeric(str_match(INFO, "age_hist_het_n_smaller=(.*?);")[,2])) %>%
  # "Count of age values falling above highest histogram bin edge for heterozygous individuals">
  mutate(">80" = as.numeric(str_match(INFO, "age_hist_het_n_larger=(.*?);")[,2])) %>% 
  
  add_row("IDs"="All individuals", "ID"="All individuals",
          "age_hist_het_bin_freq"= "3423|4546|8487|10355|12693|11933|10534|8882|5991|4136",
          "<30" = 2547, ">80" = 1935) %>%
  
  separate(col = age_hist_het_bin_freq,
           into = c("30-35","35-40","40-45","45-50","50-55","55-60","60-65","65-70","70-75","75-80"), 
           sep = "\\|", remove = TRUE, extra = "warn", fill = "right") %>% 
  mutate(across(grep("^[[:digit:]]", colnames(.)), ~ as.numeric(.))) %>% 
  
  # Filter variant found in more than 10 individuals
  mutate(nbr_individuals = rowSums(select(.,`30-35`:`>80`), na.rm = TRUE)) %>% 
  filter(nbr_individuals > 10) %>% 
  select(IDs, everything())
```

```{r, max.print = 30}
head(gnomad_decoded %>% select(IDs, "<30", "30-35","35-40","40-45","45-50","50-55","55-60","60-65","65-70","70-75","75-80", ">80", everything() ))
```

```{r}
gnomad_decoded <- gnomad_decoded %>% 
  pivot_longer(cols = c(grep("[[:digit:]]", colnames(.))), 
               names_to = "age_bin", values_to = "sample_count") %>% 
  mutate(age_bin = factor(age_bin, 
                          levels = c("<30", "30-35","35-40","40-45","45-50","50-55",
                                     "55-60","60-65","65-70","70-75","75-80", ">80"))) %>% 
  mutate(center = case_when(age_bin == "<30" ~ 15, 
                            # The average age at diagnosis is 8 overall (ages 0 to 19), 
                            # 5 years old for children (aged 0 to 14), and 17 years old 
                            # for adolescents (aged 15 to 19), while adults' average 
                            # age for cancer diagnosis is 65
                            age_bin == "30-35" ~ 32.5,
                            age_bin == "35-40" ~ 37.5,
                            age_bin == "40-45" ~ 42.5,
                            age_bin == "45-50" ~ 47.5,
                            age_bin == "50-55" ~ 52.5,
                            age_bin == "55-60" ~ 57.5,
                            age_bin == "60-65" ~ 62.5,
                            age_bin == "65-70" ~ 67.5,
                            age_bin == "70-75" ~ 72.5,
                            age_bin == "75-80" ~ 77.5,
                            TRUE ~ 90
  )) %>% 
  mutate(sample_density = sample_count / nbr_individuals) %>%
  mutate(sample_frequency = sample_count / nbr_individuals)
```
We have data on `r gnomad_decoded %>% distinct(IDs) %>% nrow` DNMT3A variants.  
<br>

The dictionary gives the "reference" distribution =  overall distribution of sample in gnomAD per bins: 2547|3423|4546|8487|10355|12693|11933|10534|8882|5991|4136|1935.  
<br>

Comparing distribution of each variant with the reference:  
I kept the results of the chi-square test in case we use it later but I didn't remove any variant
I added a t-test.

Then with the skewness test, I wanted to keep the variant as long as its distribution is shifted to the right - older age (skewness test should be > 0 - but not working great as you will see on the plots at the end) so working on that. -- Will now work on it after creating the t-test.
```{r}
goodness_fit1 <- data.frame(matrix(nrow=1, ncol=0)) 
goodness_fit2 <- data.frame(matrix(nrow=1, ncol=0)) 
skew <- data.frame(matrix(nrow=1, ncol=0)) 

for(i in unique(gnomad_decoded$IDs)) {
  
  All <- gnomad_decoded %>% filter(IDs == "All individuals") %>% select(sample_count)
  
  a <- bind_cols(gnomad_decoded %>% filter(IDs == i) %>% select(sample_count) , All) %>% 
    `colnames<-`(c(i, "All"))
  result <- chisq.test(a[,i], p=a$All, rescale.p=TRUE)$p.value
  goodness_fit1 <- rbind(goodness_fit1, result)
  
  result <- ks.test(a[,i], a$All)$p.value
  goodness_fit2 <- rbind(goodness_fit2, result)
  
  result <- skewness(a[[i]], type = 2)
  skew <- rbind(skew, result)
  
}
df <- bind_cols(goodness_fit1, goodness_fit2, skew) %>% `colnames<-`(c("chisq", "kolmogorov", "skewness"))
df$IDs <- c(unique(gnomad_decoded$IDs))

# Bind the distribution characteristic values
gnomad_decoded1 <- full_join(gnomad_decoded, df, by = "IDs") #%>% 
  # filter the significatant different
  # filter((chisq > 0.05 | kolmogorov > 0.05) )


library(diptest)
library(mixtools)
library(moments)

test_mean <- data.frame(matrix(nrow=1, ncol=0)) 
kurtosis_df <- data.frame(matrix(nrow=1, ncol=0)) 
norm_df <- data.frame(matrix(nrow=1, ncol=0)) 
ks_df <- data.frame(matrix(nrow=1, ncol=0)) 
shapiro_df <- data.frame(matrix(nrow=1, ncol=0))
# shapiro_df2 <- data.frame(matrix(nrow=1, ncol=0))
set.seed(1234)
for(i in unique(gnomad_decoded$IDs)) {
  
  All <- gnomad_decoded %>% filter(IDs == "All individuals"#,
           # age_bin != "<30",
           # age_bin != ">80"
           ) %>% 
    mutate(IDs = "Reference")
  data_plot <- gnomad_decoded %>% 
    filter(IDs == i#,
           # age_bin != "<30",
           # age_bin != ">80"
           ) %>% 
    bind_rows(., All) %>% 
    select("IDs", "age_bin", sample_frequency, center)
  
  p <- data_plot %>% 
    ggplot(aes(x = center, y= sample_frequency, color= IDs))+
    # ggplot(aes(x = age_bin, y= sample_frequency, color= IDs))+
    # geom_bar(stat = "identity", aes(alpha= IDs))
    geom_smooth(alpha= 0.5, se = FALSE, method = "loess",
                # method.args=list(family=quasibinomial)#,
                span = 0.6
    )+
    ylim(0, max(data_plot$sample_frequency))
  p_ <- layer_data(p, 1) %>% 
  mutate(colour =  as.factor(colour)) %>% 
  mutate_if(is.numeric, ~replace(., is.na(.), 0))

  # a <- p_ %>% filter(group == 1) %>% select(y)
  # b <- p_ %>% filter(group == 2) %>% select(y)
  variant <- p_ %>% filter(group == 1)
  variant <- sample(variant$x, 180, prob = variant$y, replace = TRUE)
  ref <- p_ %>% filter(group == 2)
  ref <- sample(ref$x, 180, prob = ref$y, replace = TRUE)
  
  a <- p_ %>% filter(group == 1) %>% select(y)
  aa <- a %>% drop_na()
  b <- data_plot %>% filter(IDs == i)
  c <- p_ %>% filter(group == 2) %>% select(y)
  
  kurt_res <- kurtosis(b$sample_frequency, na.rm = TRUE) # Since the kurtosis is greater than 3, this indicates that the distribution has more values in the tails compared to a normal distribution.
  kurtosis_df <- rbind(kurtosis_df, kurt_res)
  norm_res <- jarque.test(aa$y)$p.value # None are sign when using binned data, exactly same results for inferred data
  norm_df <- rbind(norm_df, norm_res)
  ks_res <- ks.test(a$y,
                   c$y)$p.value
  ks_df <- rbind(ks_df, ks_res)
  shapiro_res <- shapiro.test(b$sample_frequency)$p.value
  shapiro_df <- rbind(shapiro_df, shapiro_res)
  # shapiro_res <- shapiro.test(a$y)$p.value # Terrible on binned data
  # shapiro_df2 <- rbind(shapiro_df2, shapiro_res)

  result <- t.test(variant, ref, alternative = "greater")$p.value
  test_mean <- rbind(test_mean, result)

}
test_mean <- test_mean %>% `colnames<-`(c("t_test")) %>% 
  mutate(IDs = c(unique(gnomad_decoded$IDs)))

kurtosis_df <- kurtosis_df %>% `colnames<-`(c("kurto")) %>% 
  mutate(IDs = c(unique(gnomad_decoded$IDs)))
norm_df <- norm_df %>% `colnames<-`(c("jarque_test")) %>% 
  mutate(IDs = c(unique(gnomad_decoded$IDs)))
ks_df <- ks_df %>% `colnames<-`(c("ks_test")) %>% 
  mutate(IDs = c(unique(gnomad_decoded$IDs)))
shapiro_df <- shapiro_df %>% `colnames<-`(c("shapiro_test")) %>% 
  mutate(IDs = c(unique(gnomad_decoded$IDs)))
# shapiro_df2 <- shapiro_df2 %>% `colnames<-`(c("shapiro_test2")) %>% 
#   mutate(IDs = c(unique(gnomad_decoded$IDs)))

# Bind the distribution characteristic values
gnomad_decoded1 <- full_join(gnomad_decoded1, test_mean, by = "IDs") %>%
  full_join(., kurtosis_df, by = "IDs") %>% 
  full_join(., norm_df, by = "IDs") %>% 
  full_join(., ks_df, by = "IDs") %>% 
  full_join(., shapiro_df, by = "IDs") %>% 
  # full_join(., shapiro_df2, by = "IDs") %>% 
  # filter the significatant different
  filter(t_test > 0)

```

After this cleaning, the number of DNMT3A variants is `r gnomad_decoded1 %>% distinct(IDs) %>% nrow`.  
<!-- But I also think we can reduce their numbers by other means. For example,   -->

I extracted the VEP annotations data from `INFO`.  
But you can see that in VEP, we have multiple Variant Effect Predictor separated by a comma.
```{r}
gnomad_decoded2 <- gnomad_decoded1 %>% 
  mutate(ens_vep = str_match(INFO, ";vep=(.*?)$")[,2])

head(gnomad_decoded2 %>% select(IDs, ens_vep))[1:3,]
```
<br>

<!-- Here an example on gnomAD browser -->
```{r, out.width='100%'}
# knitr::include_graphics('/Users/colinccm/Documents/GitHub/Gillis/CH_gnomAD/variant effect predictor.jpg')
```
<br>


So I made 1 row for each Variant Effect Predictor.
```{r}
gnomad_decoded2a <- gnomad_decoded2 %>% 
  separate(col = ens_vep, paste("ens_vep", 1:25, sep=""),
           sep = ",", remove = T, extra = "warn", fill = "right") %>% 
  keep(~!all(is.na(.))) %>% 
  pivot_longer(cols = starts_with("ens_vep"), names_to = NULL, values_to = "ens_vep") %>% 
  drop_na(ens_vep)

head(gnomad_decoded2 %>% select(IDs, ens_vep))
```

For each VEP, we now have access to these information :  
`"Allele", "Consequence", "IMPACT", "SYMBOL", "Gene", "Feature_type", "Feature", "BIOTYPE", "EXON", "INTRON", "HGVSc", "HGVSp", "`
  `cDNA_position", "CDS_position", "Protein_position", "Amino_acids", "Codons", "Existing_variation", "ALLELE_NUM", "DISTANCE", "`
  `STRAND", "FLAGS", "VARIANT_CLASS", "MINIMISED", "SYMBOL_SOURCE", "HGNC_ID", "CANONICAL", "TSL", "APPRIS", "CCDS", "ENSP", "SWISSPROT", "`
  `TREMBL", "UNIPARC", "GENE_PHENO", "SIFT", "PolyPhen", "DOMAINS", "HGVS_OFFSET", "GMAF", "AFR_MAF", "AMR_MAF", "EAS_MAF", "EUR_MAF", "`
  `SAS_MAF", "AA_MAF", "EA_MAF", "ExAC_MAF", "ExAC_Adj_MAF", "ExAC_AFR_MAF", "ExAC_AMR_MAF", "ExAC_EAS_MAF", "ExAC_FIN_MAF", "`
  `ExAC_NFE_MAF", "ExAC_OTH_MAF", "ExAC_SAS_MAF", "CLIN_SIG", "SOMATIC", "PHENO", "PUBMED", "MOTIF_NAME", "MOTIF_POS", "`
  `HIGH_INF_POS", "MOTIF_SCORE_CHANGE", "LoF", "LoF_filter", "LoF_flags", "LoF_info"`  
```{r}
# Consequence annotations from Ensembl VEP
# Format: Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|
# cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|ALLELE_NUM|DISTANCE|
# STRAND|FLAGS|VARIANT_CLASS|MINIMISED|SYMBOL_SOURCE|HGNC_ID|CANONICAL|TSL|APPRIS|CCDS|ENSP|SWISSPROT|
# TREMBL|UNIPARC|GENE_PHENO|SIFT|PolyPhen|DOMAINS|HGVS_OFFSET|GMAF|AFR_MAF|AMR_MAF|EAS_MAF|EUR_MAF|
# SAS_MAF|AA_MAF|EA_MAF|ExAC_MAF|ExAC_Adj_MAF|ExAC_AFR_MAF|ExAC_AMR_MAF|ExAC_EAS_MAF|ExAC_FIN_MAF|
# ExAC_NFE_MAF|ExAC_OTH_MAF|ExAC_SAS_MAF|CLIN_SIG|SOMATIC|PHENO|PUBMED|MOTIF_NAME|MOTIF_POS|
# HIGH_INF_POS|MOTIF_SCORE_CHANGE|LoF|LoF_filter|LoF_flags|LoF_info
ens_vep_var_names <- c("Allele", "Consequence", "IMPACT", "SYMBOL", "Gene", "Feature_type", "Feature", "BIOTYPE", "EXON", "INTRON", "HGVSc", "HGVSp", "
  cDNA_position", "CDS_position", "Protein_position", "Amino_acids", "Codons", "Existing_variation", "ALLELE_NUM", "DISTANCE", "
  STRAND", "FLAGS", "VARIANT_CLASS", "MINIMISED", "SYMBOL_SOURCE", "HGNC_ID", "CANONICAL", "TSL", "APPRIS", "CCDS", "ENSP", "SWISSPROT", "
  TREMBL", "UNIPARC", "GENE_PHENO", "SIFT", "PolyPhen", "DOMAINS", "HGVS_OFFSET", "GMAF", "AFR_MAF", "AMR_MAF", "EAS_MAF", "EUR_MAF", "
  SAS_MAF", "AA_MAF", "EA_MAF", "ExAC_MAF", "ExAC_Adj_MAF", "ExAC_AFR_MAF", "ExAC_AMR_MAF", "ExAC_EAS_MAF", "ExAC_FIN_MAF", "
  ExAC_NFE_MAF", "ExAC_OTH_MAF", "ExAC_SAS_MAF", "CLIN_SIG", "SOMATIC", "PHENO", "PUBMED", "MOTIF_NAME", "MOTIF_POS", "
  HIGH_INF_POS", "MOTIF_SCORE_CHANGE", "LoF", "LoF_filter", "LoF_flags", "LoF_info")

gnomad_decoded3 <- gnomad_decoded2 %>% 
  separate(col = ens_vep, into = ens_vep_var_names,
           # paste("ens_vep", 1:100, sep=""),
           sep = "\\|", remove = F, extra = "warn", fill = "right")

head(gnomad_decoded3 %>% select(IDs, "Allele", "Consequence", "IMPACT", "SYMBOL", "Gene", "Feature_type", "Feature", "BIOTYPE", "EXON", "INTRON", "HGVSc", "HGVSp", "
  cDNA_position", "CDS_position", "Protein_position", "Amino_acids", "Codons", "Existing_variation", "ALLELE_NUM", "DISTANCE", "
  STRAND", "FLAGS", "VARIANT_CLASS", "MINIMISED", "SYMBOL_SOURCE", "HGNC_ID", "CANONICAL", "TSL", "APPRIS", "CCDS", "ENSP", "SWISSPROT", "
  TREMBL", "UNIPARC", "GENE_PHENO", "SIFT", "PolyPhen", "DOMAINS", "HGVS_OFFSET", "GMAF", "AFR_MAF", "AMR_MAF", "EAS_MAF", "EUR_MAF", "
  SAS_MAF", "AA_MAF", "EA_MAF", "ExAC_MAF", "ExAC_Adj_MAF", "ExAC_AFR_MAF", "ExAC_AMR_MAF", "ExAC_EAS_MAF", "ExAC_FIN_MAF", "
  ExAC_NFE_MAF", "ExAC_OTH_MAF", "ExAC_SAS_MAF", "CLIN_SIG", "SOMATIC", "PHENO", "PUBMED", "MOTIF_NAME", "MOTIF_POS", "
  HIGH_INF_POS", "MOTIF_SCORE_CHANGE", "LoF", "LoF_filter", "LoF_flags", "LoF_info"))
```

<!-- What are the ones you are interested in (I can keep them all of course) and how can I filter the variant we want.   -->
There is multiple type of `Consequence`.
```{r}
table(gnomad_decoded3$Consequence)

# table(gnomad_decoded3$SYMBOL)

gnomad_decoded4 <- gnomad_decoded3 %>% 
  filter(!str_detect(Consequence, "3_prime_UTR_variant|5_prime_UTR_variant") #| IDs == "All individuals"#, SYMBOL == "DNMT3A"
         )
```
I only selected the variants not in 3 and 5' for now. I am keeping everything else as you said.  
<!-- Let me know if I am correct and if I can be more selective.   -->
<!-- But we have the same thing for HGVSc, HGVSp (I think we only keep the HGVSp...) -->

# 2. Distribution plots

I found a way to create a continuous data from the binned data without assuming for a type of distribution.  
I first plotted a `geom_smooth()` plot which fit the best the binned data and used the `ggplot_build()` function to get the data set that ggplot used to plot it.  
I want to find a way to don't have < 0 value in the smooth line. Let me know if you like this way of getting the continuous data and I will work on that.  
With this continuous data, I was able to do a t-test.  
`r emo::ji("question_mark")` Question : You talked about doing a bootstrap t-test but it looks like I am able to do it with the common `t.test()` function. Should I still try a bootstrap?

<!-- In purple is the distribution of each variant. In yellow is the reference distribution. I wrote the skewness value at the bottom left. -->

```{r, fig.height= 3, fig.width=7}
data_p <- gnomad_decoded4 %>% 
  bind_rows(., gnomad_decoded1 %>% filter(IDs == "All individuals"))
n <- 0
for(i in unique(data_p$IDs)) {
  
  All <- data_p %>% filter(IDs == "All individuals"#,
           # age_bin != "<30",
           # age_bin != ">80"
           ) %>% mutate(IDs = "Reference")
  data_plot <- data_p %>% 
    filter(IDs == i#,
           # age_bin != "<30",
           # age_bin != ">80"
           )# %>% 
    # bind_rows(., All)
  n <- n + 1
  p <- data_plot %>% 
    ggplot(aes(x = center, y= sample_frequency, color= IDs))+
    geom_smooth(alpha= 0.5, se = FALSE, method = "loess",
                  # method.args=list(family=quasibinomial)#, 
                span = 0.6
                )+
    labs(title = n)+
    ylim(0, max(data_plot$sample_frequency))+

    geom_smooth(data = All, aes(x = center, y= sample_frequency, color= IDs), 
                alpha= 0.5, se = FALSE, method = "loess",
                  # method.args=list(family=quasibinomial)#,
                span = 0.6
                )+
    geom_col(data = data_plot ,aes(x= center, y= sample_frequency),
             position = "identity",
             fill = "red",
             alpha = 0.1)+
    geom_text(
      data    = data_plot,
      mapping = aes(x = -Inf, y = -Inf, label = paste0("t test = ", round(t_test, 3))),
      hjust   = 0,
      vjust   = -9
    )+
    geom_text(
      data    = data_plot,
      mapping = aes(x = -Inf, y = -Inf, label = paste0("kurtosis = ", round(kurto, 3))),
      colour = "darkblue",
      hjust   = -1,
      vjust   = -17
    )+
    geom_text(
      data    = data_plot,
      mapping = aes(x = -Inf, y = -Inf, label = paste0("jarque pval = ", round(jarque_test, 3))),
      colour = "black",
      hjust   = -2.5,
      vjust   = -17
    )+
    geom_text(
      data    = data_plot,
      mapping = aes(x = -Inf, y = -Inf, label = paste0("ks = ", round(ks_test, 3))),
      colour = "black",
      hjust   = -5,
      vjust   = -15
    )+
    geom_text(
      data    = data_plot,
      mapping = aes(x = -Inf, y = -Inf, label = paste0("shapiro test = ", round(shapiro_test, 3))),
      colour = "black",
      hjust   = -1.5,
      vjust   = -13
    )+
    # geom_text(
    #   data    = data_plot,
    #   mapping = aes(x = -Inf, y = -Inf, label = paste0("shapiro test = ", round(shapiro_test2, 3))),
    #   colour = "black",
    #   hjust   = -1.5,
    #   vjust   = -10
    # )+
    theme_minimal()
  print(p)
  p_ <- layer_data(p, 1)
  
  a <- p_ %>% filter(group == 1)
  # aa <- a %>% drop_na()
  # b <- data_plot %>% filter(IDs == i)
  # c <- p_ %>% filter(group == 2) %>% select(y)
  
  (qqplot(a$y, a$x))
  # plot(qq)

}
```

# qqplot
```{r, fig.height= 3, fig.width=3}
# for(i in unique(gnomad_decoded$IDs)) {
#   
#   All <- gnomad_decoded %>% filter(IDs == "All individuals"
#            ) %>% 
#     mutate(IDs = "Reference")
#   data_plot <- gnomad_decoded %>% 
#     filter(IDs == i
#            ) %>% 
#     bind_rows(., All) %>% 
#     select("IDs", "age_bin", sample_frequency, center)
#   
#   p <- data_plot %>% 
#     ggplot(aes(x = center, y= sample_frequency, color= IDs))+
#     geom_smooth(alpha= 0.5, se = FALSE, method = "loess",
#                 span = 0.6
#     )+
#     ylim(0, max(data_plot$sample_frequency))
#   p_ <- layer_data(p, 1)
#   
#   a <- p_ %>% filter(group == 1)
#   # aa <- a %>% drop_na()
#   # b <- data_plot %>% filter(IDs == i)
#   # c <- p_ %>% filter(group == 2) %>% select(y)
#   
#   qq <- (qqplot(a$y, a$x))
#   # plot(qq)
# 
# }
```

# Conclusion


<br>
<br>


